{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\Emails.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-058be168688f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reading in the EMAILS document as a textfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\Emails.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtextfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(textfile.read())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date Received: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\Emails.txt'"
     ]
    }
   ],
   "source": [
    "# reading in the EMAILS document as a textfile\n",
    "\n",
    "with open('\\Emails.txt', 'r') as textfile:\n",
    "    # splitting at instance of 'Date Received:'\n",
    "    text = textfile.read().split('Date Received: ')\n",
    "    print(text[:3])\n",
    "    # creating list for all fields\n",
    "    Date_Received = []\n",
    "    Response_Date = []\n",
    "    Subject = []\n",
    "    Body = []\n",
    "    for item in text:\n",
    "        # splitting the remaining text in each occurrence (all four fields appear in each instance of email)\n",
    "        # appending each field with the corresponding text in each email\n",
    "        tail = item.strip().split('Response Date:', 1)\n",
    "#         if len(tail) == 1:\n",
    "#             print(item)\n",
    "        Date_Received.append('' if len(tail) == 1 else tail[0].strip())\n",
    "        tail = tail[-1].split('Subject:', 1)\n",
    "        if Date_Received[-1] == '':\n",
    "            Date_Received[-1] = tail[0].strip()\n",
    "            Response_Date.append('')\n",
    "        else:\n",
    "            Response_Date.append('' if len(tail) == 1 else tail[0].strip())\n",
    "        tail = tail[-1].split('\\n', 1)\n",
    "        Subject.append('' if len(tail) == 1 else tail[0].strip())\n",
    "        Body.append(tail[-1].strip())\n",
    "        \n",
    "Date_Received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe from multiple lists\n",
    "# Date_Received, Response_Date, Subject, Body\n",
    "\n",
    "# 1. zip lists to create a list of tuples\n",
    "zippedList =  list(zip(Date_Received, Response_Date, Subject, Body))\n",
    "\n",
    "# 2. create a dataframe with the zipped lists\n",
    "dfObj = pd.DataFrame(zippedList, columns = ['Date_Received', 'Response_Date', 'Subject', 'Body'])  #add index?\n",
    "\n",
    "dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfObj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-69bd5cfaaf2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# rename df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0memails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfObj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# remove first row of df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfObj' is not defined"
     ]
    }
   ],
   "source": [
    "#importing data and required libraries\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import re, nltk, spacy\n",
    "\n",
    "\n",
    "# rename df\n",
    "emails = dfObj\n",
    "\n",
    "# remove first row of df\n",
    "emails = emails.iloc[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = emails.Body.values.tolist()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokenize and Clean-up using gensimâ€™s simple_preprocess()\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating vocabulary of all words in data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "count_vect = CountVectorizer(min_df=2, stop_words= text.ENGLISH_STOP_WORDS.union([\"redact\", \"nan\", \n",
    "                                                    \"www\", \"https\", \"http\", \"com\", \"request\", \"org\", \"http\", \"ish\",\n",
    "                                                                                  \"rss\",\"lda\"]))\n",
    "\n",
    "# document term matrix\n",
    "data_vectorized = count_vect.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_vectorized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-786212ee25a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_vectorized' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# sentiment analysis revealed only 4 applicable topics. so running with 4\n",
    "LDA = LatentDirichletAllocation(n_topics=4, random_state=42, learning_decay=0.5)  \n",
    "LDA.fit(data_vectorized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Search Param\n",
    "# Don't have to do this every time, ideally doing this once, then refer to above block\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "search_params = {'n_topics': [4, 5, 6, 7, 10], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "#, 'learning_decay': [.7]\n",
    "\n",
    "# Init the Model\n",
    "LDA2 = LatentDirichletAllocation(random_state=42)  \n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(LDA2, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-878a8653f697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#see best topic model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Best Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_lda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Model Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#see best topic model\n",
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'components_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-945fc2bcd6ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#printing top 10 words with highest probabilities for all topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Top 10 words for topic {}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'components_'"
     ]
    }
   ],
   "source": [
    "#printing top 10 words with highest probabilities for all topics\n",
    "for i,topic in enumerate(LDA.components_):  \n",
    "    print('Top 10 words for topic {}:'.format(i))\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[::-1][:10]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'components_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6168ce47b273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#10 words with highest probability for first topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfirst_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msecond_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mthird_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfourth_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'components_'"
     ]
    }
   ],
   "source": [
    "#10 words with highest probability for first topic\n",
    "first_topic = LDA.components_[0]\n",
    "second_topic = LDA.components_[1]\n",
    "third_topic = LDA.components_[2]\n",
    "fourth_topic = LDA.components_[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_topic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4cbb633c82b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#generate top 10 words for topic by probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtop_topic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_topic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtop_topic_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_topic' is not defined"
     ]
    }
   ],
   "source": [
    "#generate top 10 words for topic by probability\n",
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_topic_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9b9a25e777ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#retrieve value of words from count_vect object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_topic_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_topic_words' is not defined"
     ]
    }
   ],
   "source": [
    "#retrieve value of words from count_vect object\n",
    "for i in top_topic_words:  \n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study\n",
      "year\n",
      "antibiotic\n",
      "test\n",
      "borrelia\n",
      "treatment\n",
      "patient\n",
      "infection\n",
      "lyme\n",
      "disease\n"
     ]
    }
   ],
   "source": [
    "#retrieve value of words from count_vect object\n",
    "for i in top_topic_words:  \n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.86067003e-03, 9.69469744e-01, 9.74635879e-03, 1.09232267e-02],\n",
       "       [6.95513824e-02, 3.52238087e-01, 1.02986736e-01, 4.75223795e-01],\n",
       "       [2.10829261e-02, 9.34409233e-01, 2.11424681e-02, 2.33653729e-02],\n",
       "       ...,\n",
       "       [7.22888811e-03, 4.72108234e-01, 7.44997573e-03, 5.13212902e-01],\n",
       "       [5.42300397e-01, 4.56248810e-01, 7.10795726e-04, 7.39996587e-04],\n",
       "       [9.89723299e-01, 7.56572419e-04, 7.28999376e-04, 8.79112911e-03]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist = LDA.transform(data_vectorized)\n",
    "doc_topic_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.5, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_jobs=1, n_topics=5, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attributes of best_lda_model from grid search\n",
    "best_lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col0 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col0 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col3 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }</style><table id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Topic0</th>        <th class=\"col_heading level0 col1\" >Topic1</th>        <th class=\"col_heading level0 col2\" >Topic2</th>        <th class=\"col_heading level0 col3\" >Topic3</th>        <th class=\"col_heading level0 col4\" >dominant_topic</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col0\" class=\"data row0 col0\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col1\" class=\"data row0 col1\" >0.97</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col2\" class=\"data row0 col2\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col3\" class=\"data row0 col3\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col0\" class=\"data row1 col0\" >0.07</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col1\" class=\"data row1 col1\" >0.35</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col2\" class=\"data row1 col2\" >0.1</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col3\" class=\"data row1 col3\" >0.48</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row1_col4\" class=\"data row1 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col0\" class=\"data row2 col0\" >0.02</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col1\" class=\"data row2 col1\" >0.93</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col2\" class=\"data row2 col2\" >0.02</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col3\" class=\"data row2 col3\" >0.02</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col0\" class=\"data row3 col0\" >0.39</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col1\" class=\"data row3 col1\" >0.41</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col3\" class=\"data row3 col3\" >0.2</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row3_col4\" class=\"data row3 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col0\" class=\"data row4 col0\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col1\" class=\"data row4 col1\" >0.32</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col2\" class=\"data row4 col2\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col3\" class=\"data row4 col3\" >0.66</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row4_col4\" class=\"data row4 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col1\" class=\"data row5 col1\" >0.28</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col3\" class=\"data row5 col3\" >0.71</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row5_col4\" class=\"data row5 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col1\" class=\"data row6 col1\" >0.3</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col3\" class=\"data row6 col3\" >0.69</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row6_col4\" class=\"data row6 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col0\" class=\"data row7 col0\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col1\" class=\"data row7 col1\" >0.33</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col2\" class=\"data row7 col2\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col3\" class=\"data row7 col3\" >0.66</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row7_col4\" class=\"data row7 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col0\" class=\"data row8 col0\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col1\" class=\"data row8 col1\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col2\" class=\"data row8 col2\" >0.01</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col3\" class=\"data row8 col3\" >0.98</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row8_col4\" class=\"data row8 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col1\" class=\"data row9 col1\" >0.25</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col3\" class=\"data row9 col3\" >0.74</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row9_col4\" class=\"data row9 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col1\" class=\"data row10 col1\" >0.45</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col3\" class=\"data row10 col3\" >0.54</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row10_col4\" class=\"data row10 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col0\" class=\"data row11 col0\" >0.12</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col1\" class=\"data row11 col1\" >0.58</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col3\" class=\"data row11 col3\" >0.3</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row11_col4\" class=\"data row11 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col0\" class=\"data row12 col0\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col1\" class=\"data row12 col1\" >0.08</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col3\" class=\"data row12 col3\" >0.91</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row12_col4\" class=\"data row12 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col0\" class=\"data row13 col0\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col1\" class=\"data row13 col1\" >0.39</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col2\" class=\"data row13 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col3\" class=\"data row13 col3\" >0.6</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row13_col4\" class=\"data row13 col4\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col0\" class=\"data row14 col0\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col1\" class=\"data row14 col1\" >0.82</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col2\" class=\"data row14 col2\" >0</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col3\" class=\"data row14 col3\" >0.18</td>\n",
       "                        <td id=\"T_08a8fbc2_aa23_11e9_ae6e_f0189806fed5row14_col4\" class=\"data row14 col4\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x129d859e8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_topics)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sentiments for each topics: analysis to figure out which words drive the sentiment up (most associated with it)\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#polarity scores\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(snt)))\n",
    "    return snt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n",
      "neu\n"
     ]
    }
   ],
   "source": [
    "# can normally skip\n",
    "# one method of producing sentiment keys\n",
    "\n",
    "sentence=['sample_text']\n",
    "def print_sentiment_scores2(sentence):\n",
    "    ss = analyser.polarity_scores(sentence)\n",
    "#     print(ss)\n",
    "    return ss\n",
    "\n",
    "dict = print_sentiment_scores2('sample_text')\n",
    "maxVal = 0\n",
    "keyVal = ''\n",
    "for key in dict:\n",
    "    val = dict[key]\n",
    "    if(val > maxVal):\n",
    "        keyVal = key\n",
    "        maxVal = val\n",
    "print(maxVal)\n",
    "print(keyVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-afdccf408fe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# FOR RUNNING BASIC POS OR NEG ASSIGNMENT (WITHOUT PRINTED SENTIMENT KEYS AND VALUES)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_sentiment_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmaxVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "# FOR RUNNING BASIC POS OR NEG ASSIGNMENT (WITHOUT PRINTED SENTIMENT KEYS AND VALUES)\n",
    "\n",
    "for index, row in emails.iterrows():\n",
    "    dict = print_sentiment_scores(row['Body'])\n",
    "    maxVal = 0\n",
    "    keyVal = ''\n",
    "    for key in dict:\n",
    "        val = dict[key]\n",
    "        if(val > maxVal):\n",
    "            keyVal = key\n",
    "            maxVal = val\n",
    "            # assign new key and values of max value for each row\n",
    "            emails['SentimentKey'] = keyVal\n",
    "            emails['SentimentVal'] = maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c1005d66cbf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for each row in emails 'Body' column, create a dictionary to contain respective sentiment score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# create dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_sentiment_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "# FOR RUNNING BASIC POS OR NEG ASSIGNMENT (WITH PRINTED SENTIMENT KEYS AND VALUES)\n",
    "\n",
    "# for each row in emails 'Body' column, create a dictionary to contain respective sentiment score\n",
    "for index, row in emails.iterrows():\n",
    "    # create dictionary\n",
    "    dict = print_sentiment_scores(row['Body'])\n",
    "    maxVal = 0\n",
    "    keyVal = ''\n",
    "    # taking only positive or negative values from the sentiment score for each body\n",
    "    valid = set(['pos', 'neg'])\n",
    "    print(\"\")\n",
    "    print(dict)\n",
    "    print(\"\")\n",
    "    print(valid)\n",
    "    print(\"\")\n",
    "    maxVal = 0\n",
    "    maxKey = ''\n",
    "    # for each sentiment score per row with Body, find the maximum score\n",
    "    for key in valid:\n",
    "        val = dict[key]\n",
    "        if (val > maxVal):\n",
    "            maxVal = val\n",
    "            maxKey = key\n",
    "    print(maxKey)\n",
    "    print(maxVal)\n",
    "\n",
    "    emails.loc[index, 'SentimentKey'] = maxKey\n",
    "    emails.loc[index, 'SentimentVal'] = maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ae8048f57d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LDA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d2f7ae35151f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# add a column to the original data frame that will store the topic for the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtopic_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtopic_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0memails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LDA' is not defined"
     ]
    }
   ],
   "source": [
    "# add a column to the original data frame that will store the topic for the text\n",
    "topic_values = LDA.transform(data_vectorized)  \n",
    "topic_values.shape\n",
    "\n",
    "emails.shape\n",
    "\n",
    "emails['Topic'] = topic_values.argmax(axis=1)\n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    66.981132\n",
       "pos    32.075472\n",
       "        0.943396\n",
       "Name: SentimentKey, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of positive and negative comments in selected data st\n",
    "\n",
    "topics = {}\n",
    "for email in emails:\n",
    "    if topics[email['Topic']]:\n",
    "        topic = topics[email['Topic']]\n",
    "        if email['SentimentKey'] == 'pos':\n",
    "            topics[topic] = topics[topic] + 1 / 2\n",
    "# Percentage calculation for SentimentKey\n",
    "# initial calculation.....67% negative\n",
    "\n",
    "(emails['SentimentKey'].value_counts()/emails['SentimentKey'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    54.285714\n",
       "1    30.582011\n",
       "0    11.534392\n",
       "2     3.597884\n",
       "Name: Topic, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage calculation for SentimentKey by each topic\n",
    "# how do I do this?\n",
    "\n",
    "for i in np.unique(emails['Topic']):\n",
    "    #counts = emails['Topic'].value_counts().values.tolist()\n",
    "    pct = (emails['Topic'].value_counts()/emails['Topic'].count())*100\n",
    "\n",
    "    \n",
    "\n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = 0\n",
      "group 0 = 0.0% pos\n",
      "109\n",
      "name = 1\n",
      "group 1 = 0.0% pos\n",
      "289\n",
      "name = 2\n",
      "group 2 = 0.0% pos\n",
      "34\n",
      "name = 3\n",
      "group 3 = 0.0% pos\n",
      "513\n"
     ]
    }
   ],
   "source": [
    "# proportion of emails with positive sentiment across each topic\n",
    "\n",
    "for name, group in emails.groupby('Topic')['SentimentKey']:\n",
    "    print(\"name = \" + str(name))\n",
    "    countPos = 0\n",
    "    for sign in group:\n",
    "        if sign == 'pos':\n",
    "            countPos+=1\n",
    "    print(\"group \" + str(name) + \" = \" + str(countPos / group.count() * 100) + \"% pos\")\n",
    "    print(group.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.SeriesGroupBy object at 0x12bb3aac8>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.groupby('Topic')['SentimentKey']\n",
    "\n",
    "pct = (emails['Topic'].value_counts()/emails['Topic'].count())*100\n",
    "\n",
    "(emails['SentimentKey'].value_counts()/emails['SentimentKey'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-00418d625447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assignment of positive for compound score >0.5, negativer for <-0.5 and neutral for -0.5 < x < 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0memails2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memails2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "# TINKERING WITH THE FIRST SUCCESSFUL ALTERATION TO THE SENTIMENT CLASSIFICATION\n",
    "# Using a threshold of >0.5 or <-0.5 for 'compound' value\n",
    "# Assignment of positive for compound score >0.5, negativer for <-0.5 and neutral for -0.5 < x < 0.5\n",
    "\n",
    "emails2 = emails\n",
    "\n",
    "for index, row in emails2.iterrows():\n",
    "    dict = print_sentiment_scores(row['Body'])\n",
    "    valid = set(['compound'])\n",
    "    print(\"\")\n",
    "    print(dict)\n",
    "    print(\"\")\n",
    "    print(valid)\n",
    "    print(\"\")\n",
    "    # for each sentiment score per row with Body, and given criteria, assign the appropriate sentiment\n",
    "    for key in valid:\n",
    "        val = dict[key]\n",
    "        if (val > 0.5):\n",
    "            val = val\n",
    "            key = 1\n",
    "        elif (val < -0.5):\n",
    "            val = val\n",
    "            key = -1  \n",
    "        else:\n",
    "            val = val\n",
    "            key = 0\n",
    "    print(key)\n",
    "    print(val)\n",
    "    \n",
    "    #work on using the other dataset 'emails'\n",
    "    emails2.loc[index, 'SentimentKey'] = key\n",
    "    emails2.loc[index, 'SentimentVal'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Percentage\n",
      "Topic SentimentKey            \n",
      "0     -1              0.065608\n",
      "       0              0.022222\n",
      "       1              0.027513\n",
      "1     -1              0.056085\n",
      "       0              0.078307\n",
      "       1              0.171429\n",
      "2     -1              0.004233\n",
      "       0              0.013757\n",
      "       1              0.017989\n",
      "3     -1              0.159788\n",
      "       0              0.117460\n",
      "       1              0.265608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amcurtis91/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:7: FutureWarning: Interpreting tuple 'by' as a list of keys, rather than a single key. Use 'by=[...]' instead of 'by=(...)'. In the future, a tuple will always mean a single key.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# assigning distribution of sentiments across each topic\n",
    "\n",
    "print(pd.DataFrame({'Percentage': emails2.groupby(('Topic', 'SentimentKey')).size() / len(emails2)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a790cb8f84a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memails2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emails2' is not defined"
     ]
    }
   ],
   "source": [
    "emails2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    48.253968\n",
       "-1    28.571429\n",
       " 0    23.174603\n",
       "Name: SentimentKey, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage calculation for SentimentKey across entire data set\n",
    "# for function applied to each topic, look to previous assignment script (two blocks up)\n",
    "\n",
    "for i in np.unique(emails['SentimentKey']):\n",
    "    pct = (emails['SentimentKey'].value_counts()/emails['SentimentKey'].count())*100\n",
    "    \n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d36c0531e983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# emails2 has different sentimental analysis schema - positive, negative and neutral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0memails2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emails2' is not defined"
     ]
    }
   ],
   "source": [
    "# emails2 has different sentimental analysis schema - positive, negative and neutral\n",
    "\n",
    "emails2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ae8048f57d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2ffe102c3b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (emails) subset data into UP TO November 15, 2018 AND November 16, 2018 and beyond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0me_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m825\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0me_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "# (emails) subset data into UP TO November 15, 2018 AND November 16, 2018 and beyond\n",
    "\n",
    "e_first = emails.iloc[0:825]\n",
    "e_first\n",
    "\n",
    "e_second = emails.iloc[825:]\n",
    "e_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    62.787879\n",
       "neg    34.545455\n",
       "        2.666667\n",
       "Name: SentimentKey, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment distribution for first subset of emails (up to November 15, 2018)\n",
    "\n",
    "for i in np.unique(e_first['SentimentKey']):\n",
    "    pct = (e_first['SentimentKey'].value_counts()/e_first['SentimentKey'].count())*100\n",
    "    \n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    48.333333\n",
       "pos    45.833333\n",
       "        5.833333\n",
       "Name: SentimentKey, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment distribution for second subset of emails (after November 15, 2018)\n",
    "\n",
    "for i in np.unique(e_second['SentimentKey']):\n",
    "    pct = (e_second['SentimentKey'].value_counts()/e_second['SentimentKey'].count())*100\n",
    "    \n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-97e907e7a432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (emails2) subset data into UP TO November 15, 2018 AND November 16, 2018 and beyond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0me2_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memails2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m825\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0me2_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emails2' is not defined"
     ]
    }
   ],
   "source": [
    "# (emails2) subset data into UP TO November 15, 2018 AND November 16, 2018 and beyond\n",
    "\n",
    "e2_first = emails2.iloc[0:825]\n",
    "e2_first\n",
    "\n",
    "e2_second = emails2.iloc[825:]\n",
    "e2_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    50.181818\n",
       "-1    26.666667\n",
       " 0    23.151515\n",
       "Name: SentimentKey, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emails2 pt. 1 sentiment distribution\n",
    "\n",
    "for i in np.unique(e2_first['SentimentKey']):\n",
    "    pct = (e2_first['SentimentKey'].value_counts()/e2_first['SentimentKey'].count())*100\n",
    "    \n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    41.666667\n",
       " 1    35.000000\n",
       " 0    23.333333\n",
       "Name: SentimentKey, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emails2 pt. 2 sentiment distribution\n",
    "\n",
    "for i in np.unique(e2_second['SentimentKey']):\n",
    "    pct = (e2_second['SentimentKey'].value_counts()/e2_second['SentimentKey'].count())*100\n",
    "    \n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    48.253968\n",
       "-1    28.571429\n",
       " 0    23.174603\n",
       "Name: SentimentKey, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_tot = (emails2['SentimentKey'].value_counts()/emails2['SentimentKey'].count())*100\n",
    "pct_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Percentage\n",
      "Topic SentimentKey            \n",
      "0     -1              0.036364\n",
      "       0              0.015758\n",
      "       1              0.024242\n",
      "1     -1              0.058182\n",
      "       0              0.082424\n",
      "       1              0.179394\n",
      "2     -1              0.004848\n",
      "       0              0.014545\n",
      "       1              0.020606\n",
      "3     -1              0.167273\n",
      "       0              0.118788\n",
      "       1              0.277576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amcurtis91/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:1: FutureWarning: Interpreting tuple 'by' as a list of keys, rather than a single key. Use 'by=[...]' instead of 'by=(...)'. In the future, a tuple will always mean a single key.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({'Percentage': e2_first.groupby(('Topic', 'SentimentKey')).size() / len(e2_first)}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
